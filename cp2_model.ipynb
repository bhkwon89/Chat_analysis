{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1SFvjQB_yfk2JA1ZaIFSIK244VrQP1FWL",
      "authorship_tag": "ABX9TyPHmDFG4VBnqtL9hPHfaUsM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhkwon89/cp2/blob/main/cp2_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GYz7SvR5uc_",
        "outputId": "a496ed3c-7547-4c70-ac56-18752b8e723a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "situation_code = {\n",
        "    1: '가족관계',\n",
        "    2: '학업 및 진로',\n",
        "    3: '학교폭력/따돌림',\n",
        "    4: '대인관계',\n",
        "    5: '연애,결혼,출산',\n",
        "    6: '진로,취업,직장',\n",
        "    7: '대인관계(부부,자녀)',\n",
        "    8: '은퇴, 노후준비',\n",
        "    9: '건강',\n",
        "    10: '직작,업무,스트레스',\n",
        "    11: '건강,죽음',\n",
        "    12: '대인관계(노년)',\n",
        "    13: '재정' \n",
        "}\n",
        "\n",
        "\n",
        "emotion_code = {\n",
        "    10: '분노',\n",
        "    11: '툴툴대는',\n",
        "    12: '좌절한',\n",
        "    13: '짜증내는',\n",
        "    14: '방어적인',\n",
        "    15: '악의적인',\n",
        "    16: '안달하는',\n",
        "    17: '구역질나는',\n",
        "    18: '노여워하는',\n",
        "    19: '성가신',\n",
        "    20: '슬픔',\n",
        "    21: '실망한',\n",
        "    22: '비통한',\n",
        "    23: '후회되는',\n",
        "    24: '우울한',\n",
        "    25: '마비된',\n",
        "    26: '염세적인',\n",
        "    27: '눈물이 나는',\n",
        "    28: '낙담한',\n",
        "    29: '환멸을 느끼는',\n",
        "    30: '불안',\n",
        "    31: '두려운',\n",
        "    32: '스트레스 받는',\n",
        "    33: '취약한',\n",
        "    34: '혼란스러운',\n",
        "    35: '당혹스러운',\n",
        "    36: '회의적인',\n",
        "    37: '걱정스러운',\n",
        "    38: '조심스러운',\n",
        "    39: '초조한',\n",
        "    40: '상처',\n",
        "    41: '질투',\n",
        "    42: '배신당한',\n",
        "    43: '고립된',\n",
        "    44: '충격 받은',\n",
        "    45: '가난한, 불우한',\n",
        "    46: '희생된',\n",
        "    47: '억울한',\n",
        "    48: '괴로워하는',\n",
        "    49: '버려진',\n",
        "    50: '당황',\n",
        "    51: '고립된(당황한)',\n",
        "    52: '남의 시선을 의식하는',\n",
        "    53: '외로운',\n",
        "    54: '열등감',\n",
        "    55: '죄책감의',\n",
        "    56: '부끄러운',\n",
        "    57: '혐오스러운',\n",
        "    58: '한심한',\n",
        "    59: '혼란스러운',\n",
        "    60: '기쁨',\n",
        "    61: '감사하는',\n",
        "    62: '신뢰하는',\n",
        "    63: '편안한',\n",
        "    64: '만족스러운',\n",
        "    65: '흥분',\n",
        "    66: '느긋',\n",
        "    67: '안도',\n",
        "    68: '신이 난',\n",
        "    69: '자신하는'\n",
        "}\n"
      ],
      "metadata": {
        "id": "tpjCwxCRKAaO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonnlp pandas tqdm   \n",
        "!pip install mxnet\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "\n"
      ],
      "metadata": {
        "id": "PLX7W1GWLw2x",
        "outputId": "080e5034-6874-4821-d249-677262564f58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.7.0.post2)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "id": "YSK5YScr23s6",
        "outputId": "53f22777-771f-4383-885c-f9988d037d21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-p32u8kdn/kobert-tokenizer_f0c970be4d9d4b61903f1e4b4ca7a839\n",
            "  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-p32u8kdn/kobert-tokenizer_f0c970be4d9d4b61903f1e4b4ca7a839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "eICsLhNs3K4S",
        "outputId": "23379fca-2ab5-4803-8437-1fb2d94a33db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-jnt_pfbq\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-jnt_pfbq\n",
            "Requirement already satisfied: boto3<=1.15.18 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.15.18)\n",
            "Requirement already satisfied: gluonnlp<=0.10.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet<=1.7.0.post2,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.7.0.post2)\n",
            "Requirement already satisfied: onnxruntime<=1.8.0,==1.8.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece<=0.1.96,>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch<=1.10.1,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.1)\n",
            "Requirement already satisfied: transformers<=4.8.1,>=4.8.1 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime<=1.8.0,==1.8.0->kobert==0.2.3) (2.0.7)\n",
            "Requirement already satisfied: botocore<1.19.0,>=1.18.18 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (1.18.18)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.3.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3<=1.15.18->kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (0.29.32)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.19.0,>=1.18.18->boto3<=1.15.18->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<=1.7.0.post2,>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<=1.10.1,>=1.7.0->kobert==0.2.3) (4.1.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.12.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (4.64.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (0.0.53)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp<=0.10.0,>=0.6.0->kobert==0.2.3) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.8.1,>=4.8.1->kobert==0.2.3) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from kobert import get_tokenizer\n",
        "from kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "Ndfh3pjgLyub"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n",
        "tok = tokenizer.tokenize\n",
        "\n",
        "# Setting parameters\n",
        "max_len = 256\n",
        "batch_size = 16\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 10\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "Bk1DkuheWPRs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer,vocab, max_len,\n",
        "                 pad, pair):\n",
        "   \n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
        "        \n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "S54FtpEHpB1b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=6,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "4vB6PPxbc8Yx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "def predict(sentence):\n",
        "    dataset = [[sentence, '0']]\n",
        "    test = BERTDataset(dataset, 0, 1, tok, vocab, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=2)\n",
        "    model.eval()\n",
        "    answer = 0\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        for logits in out:\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            answer = np.argmax(logits)\n",
        "    return answer"
      ],
      "metadata": {
        "id": "G0sZTuZYdArJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.read_excel('/content/drive/MyDrive/cp2/dataset/감성대화말뭉치(최종데이터)_Training.xlsx')\n",
        "validation_set = pd.read_excel('/content/drive/MyDrive/cp2/dataset/감성대화말뭉치(최종데이터)_Validation.xlsx')"
      ],
      "metadata": {
        "id": "7aXZOZnjGGGX"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set.fillna(' ')\n",
        "validation_set = validation_set.fillna(' ')"
      ],
      "metadata": {
        "id": "84FA3FpN2gQT"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def make_data(df):\n",
        "#   df_result = pd.DataFrame()\n",
        "#   for i in range(len(df)):\n",
        "#     text1 = (df['사람문장1'][i] + ' ' + df['시스템응답1'][i]  + ' ' + \n",
        "#                    df['사람문장2'][i]+ ' ' + df['시스템응답2'][i] + ' ' + \n",
        "#                    df['사람문장3'][i] + ' ' + df['시스템응답3'][i])\n",
        "    \n",
        "#     text2 = (df['사람문장2'][i] + ' ' + df['시스템응답2'][i] + ' ' + \n",
        "#                    df['사람문장3'][i] + ' ' + df['시스템응답3'][i] + ' ' +\n",
        "#                    df['사람문장4'][i] + ' ' + df['시스템응답4'][i])\n",
        "    \n",
        "#     df_result = df_result.append(pd.DataFrame({'감정_대분류': [df['감정_대분류'][i]], '문장': [text1]}))\n",
        "#     df_result = df_result.append(pd.DataFrame({'감정_대분류': [df['감정_대분류'][i]], '문장': [text2]}))\n",
        "\n",
        "#   return df_result"
      ],
      "metadata": {
        "id": "sg-s5aA7yi2h"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_set = make_data(train_set)\n",
        "# train_set.to_csv('/content/drive/MyDrive/cp2/dataset/감성대화말뭉치(최종데이터)_Training2.xlsx')"
      ],
      "metadata": {
        "id": "tkF6RxgfzOnd"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.read_csv('/content/drive/MyDrive/cp2/dataset/감성대화말뭉치(최종데이터)_Training2.xlsx', index_col=0)"
      ],
      "metadata": {
        "id": "phiwbMpMCody"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_set['감정_대분류'].unique()"
      ],
      "metadata": {
        "id": "WKpSAUGaFKId",
        "outputId": "3c032a9e-c290-4496-f26d-0d992319c9be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['분노', '슬픔', '불안', '당황', '상처', '기쁨'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['감정_대분류'].replace('기쁨 ', '기쁨', inplace=True)\n",
        "train_set['감정_대분류'].replace('불안 ', '불안', inplace=True)"
      ],
      "metadata": {
        "id": "LvdEL9vazb59"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set['감정_대분류'].unique()"
      ],
      "metadata": {
        "id": "wxGmnc3dFZnY",
        "outputId": "6119ec75-13e3-41d7-e36f-4a76ad4573eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['기쁨', '불안', '당황', '슬픔', '분노', '상처'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_set['문장'] = (train_set['사람문장1'] + ' ' + train_set['시스템응답1']  + ' ' + \n",
        "#                    train_set['사람문장2'] + ' ' + train_set['시스템응답2'] + ' ' + \n",
        "#                    train_set['사람문장3'] + ' ' + train_set['시스템응답3'] + \n",
        "#                    train_set['사람문장4'] + ' ' + train_set['시스템응답4'])\n",
        "validation_set['문장'] = (validation_set['사람문장1'] + ' ' + validation_set['시스템응답1']  + ' ' +\n",
        "                        validation_set['사람문장2'] + ' ' + validation_set['시스템응답2'] + ' ' + \n",
        "                        validation_set['사람문장3'] + ' ' + validation_set['시스템응답3'] + ' ' +\n",
        "                        validation_set['사람문장4'] + ' ' + validation_set['시스템응답4'] )"
      ],
      "metadata": {
        "id": "f1TRl_Rj2rXv"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_set = train_set.loc[:, ['감정_대분류', '문장']]\n",
        "validation_set = validation_set.loc[:, ['감정_대분류', '문장']]\n",
        "\n",
        "train_set.dropna(inplace=True)\n",
        "validation_set.dropna(inplace=True)\n",
        "train_set.columns = ['label', 'data']\n",
        "validation_set.columns = ['label', 'data']\n",
        "\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "train_set['label'] = le.fit_transform(train_set['label'])\n",
        "validation_set['label'] = le.transform(validation_set['label'])"
      ],
      "metadata": {
        "id": "iBOJU6h92UDZ"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "id": "j3z4677fDrPO",
        "outputId": "d002ef51-41d9-492f-9b41-064b3ffab319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['기쁨', '당황', '분노', '불안', '상처', '슬픔'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set"
      ],
      "metadata": {
        "id": "Xdf0Fw13CbMu",
        "outputId": "0220bad0-e362-424a-ddca-d94b3507c80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                               data\n",
              "0       0  아내가 드디어 출산하게 되어서 정말 신이 나. 아내분이 출산을 하시는군요. 정말 축...\n",
              "0       0  아 지금 정말 신이 나. 잘 된 일이네요. 아기가 점점 클게 벌써 기대가 되네. 내...\n",
              "0       3  당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야. 약 종류가 ...\n",
              "0       3  건강할 때 관리 좀 잘할걸 하는 생각이 들더라고. 현재 상황에서 변화를 주기 위해 ...\n",
              "0       1  고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워. 고등학교 수...\n",
              "..    ...                                                ...\n",
              "0       5  내 재능이 남들보다 월등한 거는 아니라면서 취업해서 안정적으로 살았으면 좋겠다고 하...\n",
              "0       0  이렇게 좋은 운동 시설에서 경로 우대로 운동할 수 있다니 참 행운이야. 운동 시설을...\n",
              "0       0  덕분에 건강도 챙길 수 있고 너무 좋아. 안마기도 있던데 내일은 운동하고 안마기도 ...\n",
              "0       3  친구 관계가 너무 힘들어. 베푸는 만큼 돌아오지 않는 것 같아. 많이 서운하셨겠어요...\n",
              "0       3  카페에 가서 대화하거나 같이 술 마시면서 이야기했던 것 같아. 대화로 문제를 해결해...\n",
              "\n",
              "[81758 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da7dd173-c32e-43b7-90e0-30b630b92cd5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>아내가 드디어 출산하게 되어서 정말 신이 나. 아내분이 출산을 하시는군요. 정말 축...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>아 지금 정말 신이 나. 잘 된 일이네요. 아기가 점점 클게 벌써 기대가 되네. 내...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>당뇨랑 합병증 때문에 먹어야 할 약이 열 가지가 넘어가니까 스트레스야. 약 종류가 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>건강할 때 관리 좀 잘할걸 하는 생각이 들더라고. 현재 상황에서 변화를 주기 위해 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>고등학교에 올라오니 중학교 때보다 수업이 갑자기 어려워져서 당황스러워. 고등학교 수...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>내 재능이 남들보다 월등한 거는 아니라면서 취업해서 안정적으로 살았으면 좋겠다고 하...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>이렇게 좋은 운동 시설에서 경로 우대로 운동할 수 있다니 참 행운이야. 운동 시설을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>덕분에 건강도 챙길 수 있고 너무 좋아. 안마기도 있던데 내일은 운동하고 안마기도 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>친구 관계가 너무 힘들어. 베푸는 만큼 돌아오지 않는 것 같아. 많이 서운하셨겠어요...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>카페에 가서 대화하거나 같이 술 마시면서 이야기했던 것 같아. 대화로 문제를 해결해...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>81758 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da7dd173-c32e-43b7-90e0-30b630b92cd5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da7dd173-c32e-43b7-90e0-30b630b92cd5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da7dd173-c32e-43b7-90e0-30b630b92cd5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_data = [[i, str(j)] for i, j in zip(train_set['data'], train_set['label'])]\n",
        "validation_set_data = [[i, str(j)] for i, j in zip(validation_set['data'], validation_set['label'])]\n",
        "\n",
        "train_set_data, test_set_data = train_test_split(train_set_data, test_size = 0.2, random_state=4)\n",
        "\n",
        "train_set_data = BERTDataset(train_set_data, 0, 1, tok, vocab, max_len, True, False)\n",
        "test_set_data = BERTDataset(test_set_data, 0, 1, tok, vocab, max_len, True, False)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_set_data, batch_size=batch_size, num_workers=2)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_set_data, batch_size=batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "Y2TzfQf5Nfvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "id": "SSJX9SKmN7kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, f'/content/drive/MyDrive/Colab Notebooks/SentimentAnalysisKOBert.pt')\n",
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/Colab Notebooks/SentimentAnalysisKOBert_StateDict.pt')"
      ],
      "metadata": {
        "id": "K4agE1BHhsRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZ0f5-7LsU80"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}